---
title: "Multiple linear regression"
author: "Fomba Kassoh: I worked with Souleymane Doumbia on this lab"
output:
  pdf_document: default
  html_document:
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Grading the professor

Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, "Beauty in the classroom: instructors' pulchritude and putative pedagogical productivity" by Hamermesh and Parker found that instructors who are viewed to be better looking receive higher instructional ratings. 

Here, you will analyze the data from this study in order to learn what goes into a positive professor evaluation.

## Getting Started

### Load packages

In this lab, you will explore and visualize the data using the **tidyverse** suite of packages. The data can be found in the companion package for OpenIntro resources, **openintro**.

Let's load the packages.

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(GGally)
```

This is the first time we're using the `GGally` package. You will be using the `ggpairs` function from this package later in the lab.

### The data

The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors' physical appearance. The result is a data frame where each row contains a different course and columns represent variables about the courses and professors. It's called `evals`.

```{r}
data("evals", package = 'openintro')
glimpse(evals)
```

We have observations on 21 different variables, some categorical and some numerical. The meaning of each variable can be found by bringing up the help file:

```{r help-evals, eval=FALSE}
?evals
```

## Exploring the data

1.  Is this an observational study or an experiment? The original research
    question posed in the paper is whether beauty leads directly to the
    differences in course evaluations. Given the study design, is it possible to
    answer this question as it is phrased? If not, rephrase the question.

**Insert your answer here**
The study is an observational study, not an experiment.The question implies a causal relationship, that is, beauty directly causes differences in course evaluations. A more appropriate question that aligns with the design of an observational study would be:

"Is there a correlation between the perceived beauty of professors and their course evaluations at the University of Texas at Austin?".

2.  Describe the distribution of `score`. Is the distribution skewed? What does 
    that tell you about how students rate courses? Is this what you expected to 
    see? Why, or why not?

**Insert your answer here**

The distribution of course scores can be characterized based on the histogram, box plot, and the statistical summary:

**Histogram and Skewness:** The histogram shows that the distribution of scores is slightly left-skewed (negatively skewed). This indicates that while most of the scores are high, there is a longer tail on the lower end of the scale.

**Box Plot Analysis:** The box plot further confirms the skewness, with the median closer to the upper quartile and a longer lower whisker. There are no significant outliers on the higher end, but a few on the lower end.

**Statistical Summary:**
*Mean:* The average score is approximately 4.17.
Standard Deviation: The standard deviation is about 0.54, suggesting some variation in the scores but not excessively wide.
*Min and Max:* The scores range from a minimum of 2.3 to a maximum of 5.0.
Quartiles: The 25th percentile is at 3.8, the median (50th percentile) is at 4.3, and the 75th percentile is at 4.6.

Interpretation Regarding Course Ratings:
The skewness of the distribution indicates that students generally tend to rate courses relatively high, with fewer courses receiving lower scores.The presence of a tail on the lower end suggests that while most courses are rated well, there are some courses that receive significantly lower ratings.

**Expectations:**
This distribution aligns with common trends observed in educational course evaluations, where students often tend to give moderately high to high ratings. It's not unusual for rating distributions in such contexts to be left-skewed, as extreme dissatisfaction is typically less common.

```{r}
library(ggplot2)
library(dplyr)

# Plot a histogram distribution
p1 <- ggplot(evals, aes(x=score)) + 
      geom_histogram(aes(y=..density..), bins=30, fill="blue", color="black") +
      geom_density(alpha=.2, fill="#FF6666") +
      ggtitle("Histogram of Course Scores")

# Plot a box plot distribution
p2 <- ggplot(evals, aes(x="", y=score)) + 
      geom_boxplot(fill="tomato", color="black") +
      ggtitle("Box Plot of Course Scores") +
      theme(axis.title.x=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks.x=element_blank())

# Arrange the plots in one window
library(gridExtra)
grid.arrange(p1, p2, ncol=2)

# Statistical summary of the 'score' column
score_description <- summary(evals$score)

# Print the statistical summary
print(score_description)


```

3.  Excluding `score`, select two other variables and describe their relationship 
    with each other using an appropriate visualization.

**Insert your answer here**
From the available variables, two interesting variables to analyze could be:

age: The age of the professor.
cls_students: The number of students in the class

The relationship between a professor's age and the class size they teach does not exhibit a clear pattern or trend.

```{r}
library(ggplot2)

# Create a scatter plot to analyze the relationship between 'age' and 'cls_students'
ggplot(evals, aes(x=age, y=cls_students)) +
  geom_point() +
  ggtitle('Relationship between Professor Age and Class Size') +
  xlab('Age of Professor') +
  ylab('Number of Students in Class') +
  theme_minimal()

```

## Simple linear regression

The fundamental phenomenon suggested by the study is that better looking teachers are evaluated more favorably. Let's create a scatterplot to see if this appears to be the case:

```{r scatter-score-bty_avg}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_point() + 
  labs(title = 'Relationship between Beauty Score and Course Evaluation Score', x = 'Average Beauty Score', y = 'Course Evaluation Score')

```

Before you draw conclusions about the trend, compare the number of observations in the data frame with the approximate number of points on the scatterplot. Is anything awry?

4.  Replot the scatterplot, but this time use `geom_jitter` as your layer. What 
    was misleading about the initial scatterplot?

```{r scatter-score-bty_avg-jitter}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter() + 
  labs(title = 'Relationship between Beauty Score and Course Evaluation Score', x = 'Average Beauty Score', y = 'Course Evaluation Score')
```

**Insert your answer here**
There are 463 observations in the dataset. By observing the scatter plot, it appears that there are fewer points than 463 which is misleading. This could be due to multiple data points overlapping at the same coordinates.

```{r}
evals %>%
  nrow()
```

5.  Let's see if the apparent trend in the plot is something more than
    natural variation. Fit a linear model called `m_bty` to predict average
    professor score by average beauty rating. Write out the equation for the linear 
    model and interpret the slope. Is average beauty score a statistically significant
    predictor? Does it appear to be a practically significant predictor?
    
**Insert your answer here**
Linear model, equation, and interpretations as shown below.

**Interpretation of slope:** For each one-unit increase in the average beauty score, the average professor score is expected to increase by approximately 0.06664.

**Statistical Significance:** The p-value in the linear model is 5.08Ã—10^-05. The p-value is significantly less than 0.05. This indicates that the average beauty score is a statistically significant predictor of the average professor score in this dataset.

While the average beauty score statistically significantly predicts the professor score, the practical significance of this effect may be considered relatively small because the slope value (0.06664) suggests that the effect size is modest.

```{r scatter-score-bty_avg_pic-color}
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
```
\[
  \hat{y} = 3.88034 + 0.06664 \times bty\_avg
\]


Add the line of the bet fit model to your plot using the following:
    
```{r scatter-score-bty_avg-line-se}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  geom_smooth(method = "lm")
```

The blue line is the model. The shaded gray area around the line tells you about the variability you might expect in your predictions. To turn that off, use `se = FALSE`.

```{r scatter-score-bty_avg-line}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE)
```

6.  Use residual plots to evaluate whether the conditions of least squares
    regression are reasonable. Provide plots and comments for each one (see
    the Simple Regression Lab for a reminder of how to make these).

**Insert your answer here**
Below are the plots and comments.

**Residuals vs Fitted Values Plot:** In this plot, there does not appear to be a clear, systematic pattern in the residuals, which is a good sign for linearity. Also, the plot shows a fairly consistent spread of residuals across the range of fitted values, indicating that the assumption of homoscedasticity may be reasonable.

**Normal Q-Q Plot of Residuals:** The points in this Q-Q plot generally follow the line, especially in the middle of the distribution. There are some deviations at the ends, but these are not extreme. This suggests that the normality assumption is not strongly violated. However, the slight deviations at the ends indicate that the residuals may not be perfectly normally distributed.

```{r}
library(ggplot2)

# Calculate residuals and fitted values
fitted_values <- fitted(m_bty)
residuals <- residuals(m_bty)

# Create a data frame for plotting
plot_data <- data.frame(Fitted_Values = fitted_values, Residuals = residuals)

# Plot residuals vs fitted values
p1 <- ggplot(plot_data, aes(x = Fitted_Values, y = Residuals)) +
      geom_point() +
      geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
      xlab("Fitted Values") +
      ylab("Residuals") +
      ggtitle("Residuals vs Fitted Values")

# Plot Q-Q plot for residuals
p2 <- ggplot(plot_data, aes(sample = Residuals)) +
      stat_qq() +
      stat_qq_line(color = "red") +
      ggtitle("Normal Q-Q Plot of Residuals")

# Arrange the plots side by side
library(gridExtra)
grid.arrange(p1, p2, ncol = 2)

```

## Multiple linear regression

The data set contains several variables on the beauty score of the professor: individual ratings from each of the six students who were asked to score the physical appearance of the professors and the average of these six scores. Let's take a look at the relationship between one of these scores and the average beauty score.

```{r bty-rel}
ggplot(data = evals, aes(x = bty_f1lower, y = bty_avg)) +
  geom_point()

evals %>% 
  summarise(cor(bty_avg, bty_f1lower))
```

As expected, the relationship is quite strong---after all, the average score is calculated using the individual scores. You can actually look at the relationships between all beauty variables (columns 13 through 19) using the following command:

```{r bty-rels}
evals %>%
  select(contains("bty")) %>%
  ggpairs()
```

These variables are collinear (correlated), and adding more than one of these variables to the model would not add much value to the model. In this application and with these highly-correlated predictors, it is reasonable to use the average beauty score as the single representative of these variables.

In order to see if beauty is still a significant predictor of professor score after you've accounted for the professor's gender, you can add the gender term into the model.

```{r scatter-score-bty_avg_pic-color}
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
```

7.  P-values and parameter estimates should only be trusted if the
    conditions for the regression are reasonable. Verify that the conditions
    for this model are reasonable using diagnostic plots.

**Insert your answer here**
Here are the diagnostic plots for the multiple linear regression model:

**Residuals vs Fitted Values Plot:**
There doesn't appear to be a clear pattern in the residuals, which is good for the assumption of linearity. The spread of residuals seems relatively constant across the range of fitted values, supporting the homoscedasticity assumption.

**Normal Q-Q Plot:**
The points largely follow the line, especially in the middle of the distribution, indicating that the residuals are approximately normally distributed. Some deviations at the ends are observed but are not extreme.

**Scale-Location Plot:**
The spread of residuals appears consistent across the range of fitted values, which supports the assumption of constant variance.

**Residuals vs Leverage Plot:**
Most data points have low leverage, and there donâ€™t appear to be any points with both high leverage and large residuals, which would be indicative of influential cases.

These diagnostic plots suggest that the assumptions of linearity, independence, homoscedasticity, and normality are reasonably met for this multiple linear regression model.
```{r}
library(ggplot2)
library(gridExtra)
library(stats)


fitted_values_multi <- fitted(m_bty_gen)
residuals_multi <- residuals(m_bty_gen)

# 1. Residuals vs Fitted Values Plot
p1 <- ggplot() +
      geom_point(aes(x=fitted_values_multi, y=residuals_multi)) +
      geom_hline(yintercept=0, color="red", linetype="dashed") +
      xlab("Fitted Values") + ylab("Residuals") +
      ggtitle("Residuals vs Fitted Values")

# 2. Normal Q-Q Plot
p2 <- ggplot() +
      stat_qq(aes(sample=residuals_multi)) +
      geom_abline(slope=1, intercept=0, color="red", linetype="dashed") +
      ggtitle("Normal Q-Q Plot")

# 3. Scale-Location Plot
p3 <- ggplot() +
      geom_point(aes(x=fitted_values_multi, y=sqrt(abs(residuals_multi)))) +
      xlab("Fitted Values") + ylab("Sqrt(|Residuals|)") +
      ggtitle("Scale-Location Plot")

# 4. Residuals vs Leverage Plot
leverage <- hatvalues(m_bty_gen)
p4 <- ggplot() +
      geom_point(aes(x=leverage, y=residuals_multi)) +
      xlab("Leverage") + ylab("Residuals") +
      ggtitle("Residuals vs Leverage")

# Arrange plots in a 2x2 grid
grid.arrange(p1, p2, p3, p4, nrow=2)
```


8.  Is `bty_avg` still a significant predictor of `score`? Has the addition
    of `gender` to the model changed the parameter estimate for `bty_avg`?

**Insert your answer here**
Based on the coefficients and p-values above, bty_avg remains a significant predictor of score even after accounting for gender. The addition of gender to the model affects the parameter estimate for bty_avg, although the change is relatively small. The inclusion of gender reveals its own significant effect on the professor score.

Summary of parameters:
Coefficient of bty_avg: 0.0742
P-value of bty_avg: 6.48 Ã— 10^-6

Coefficient of gender: 0.1724
P-value of gender[T.male]: 0.00065






Note that the estimate for `gender` is now called `gendermale`. You'll see this name change whenever you introduce a categorical variable. The reason is that R recodes `gender` from having the values of `male` and `female` to being an indicator variable called `gendermale` that takes a value of $0$ for female professors and a value of $1$ for male professors. (Such variables are often referred to as "dummy" variables.)

As a result, for female professors, the parameter estimate is multiplied by zero, leaving the intercept and slope form familiar from simple regression.

\[
  \begin{aligned}
\widehat{score} &= \hat{\beta}_0 + \hat{\beta}_1 \times bty\_avg + \hat{\beta}_2 \times (0) \\
&= \hat{\beta}_0 + \hat{\beta}_1 \times bty\_avg\end{aligned}
\]

<!-- We can plot this line and the line corresponding to those with color pictures
with the following  -->
<!-- custom function. -->

```{r twoLines}
ggplot(data = evals, aes(x = bty_avg, y = score, color = pic_color)) +
 geom_smooth(method = "lm", formula = y ~ x, se = FALSE)
```

9.  What is the equation of the line corresponding to those with color pictures? 
    (*Hint:* For those with color pictures, the parameter estimate is multiplied
    by 1.) For two professors who received the same beauty rating, which color 
    picture tends to have the higher course evaluation score?

**Insert your answer here**
The equation of the line corresponding to those with color pictures is shown below.Based on the equation, the balck and white color picture tend to have the higher course evaluation score because the coefficient corresponding to color picture is negative which have the effect of reducing the course evaluation score.
```{r}
# Fit the linear model
model_color <- lm(score ~ bty_avg + gender + pic_color, data = evals)

# Get the summary of the model
model_summary_color <- summary(model_color)
print(model_summary_color)

```
**equation**

\[
  \hat{y} = 3.95031 + 0.06664 \times bty\_avg + 0.18750 - 0.18851
\]


The decision to call the indicator variable `gendermale` instead of `genderfemale` has no deeper meaning. R simply codes the category that comes first alphabetically as a $0$. (You can change the reference level of a categorical variable, which is the level that is coded as a 0, using the`relevel()` function. Use `?relevel` to learn more.)

10. Create a new model called `m_bty_rank` with `gender` removed and `rank` 
    added in. How does R appear to handle categorical variables that have more 
    than two levels? Note that the rank variable has three levels: `teaching`, 
    `tenure track`, `tenured`.

**Insert your answer here**
R appears to treat teaching as the baseline category. That is, it multiply the the coefficient for teaching by $0$. The model only generates coefficients for bty_avg, tenure track, and tenured by multiplying their respective coefficients by $1$. The equations for predicting the score based on the category of rank and bty_avg are as follows:

**equation for teaching** 
\[
  \widehat{score} = 3.98155 + 0.06783 \times bty\_avg
\]

**equation for tenure track**
\[
  \widehat{score} = 3.98155 + 0.06783 \times bty\_avg - 0.06783
\]0.16070

**equation for tenured**
\[
  \widehat{score} = 3.98155 + 0.06783 \times bty\_avg - 0.12623
\]0.16070
```{r}

# Fit the linear model
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)

# Get the summary of the model
model_summary_bty_rank <- summary(m_bty_rank)
print(model_summary_bty_rank)

```

The interpretation of the coefficients in multiple regression is slightly different from that of simple regression. The estimate for `bty_avg` reflects how much higher a group of professors is expected to score if they have a beauty rating that is one point higher *while holding all other variables constant*. In this case, that translates into considering only professors of the same rank with `bty_avg` scores that are one point apart.

## The search for the best model

We will start with a full model that predicts professor score based on rank, gender, ethnicity, language of the university where they got their degree, age, proportion of students that filled out evaluations, class size, course level, number of professors, number of credits, average beauty rating, outfit, and picture color.

11. Which variable would you expect to have the highest p-value in this model? 
    Why? *Hint:* Think about which variable would you expect to not have any 
    association with the professor score.

**Insert your answer here**

I expect cls_profs to have the highest p-value. While class size or the number of professors could impact scores, these are more indirectly related compared to individual characteristics of the professor or class level. Therefore, cls_profs would not be expected to have a significant impact on professor score.



Let's run the model...

```{r m_full, tidy = FALSE}
m_full <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg 
             + pic_outfit + pic_color, data = evals)
```

12. Check your suspicions from the previous exercise. Include the model output
    in your response.

**Insert your answer here**
My suspicion is in agreement with the model. The fact that cls_profs variable has the highest p-value suggests that the number of professors teaching a class (single vs. multiple) might not significantly impact how students evaluate the course or professor.

```{r m_full, tidy = FALSE}
m_full <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg 
             + pic_outfit + pic_color, data = evals)
summary(m_full)
```
13. Interpret the coefficient associated with the ethnicity variable.

**Insert your answer here**
***Interpretation of "Ethnicity of professor: not minority, minority."***
This coefficient, 0.1234929, suggests that, on average, non-minority professors are expected to have a score that is 0.1234929 points higher than minority professors, holding all other variables constant. It reflects the difference in the average score attributed to the ethnicity of the professor, under the assumption that all other factors (like beauty score, rank, gender, etc.) are the same for the compared groups. The positive coefficient indicates a favorability towards non-minority professors in terms of how they are scored, according to this model.


14. Drop the variable with the highest p-value and re-fit the model. Did the
    coefficients and significance of the other explanatory variables change?
    (One of the things that makes multiple regression interesting is that
    coefficient estimates depend on the other variables that are included in
    the model.) If not, what does this say about whether or not the dropped
    variable was collinear with the other explanatory variables?

**Insert your answer here**
There is no change in the p-value which implies that there is no change in the significance. Similarly, there is no significant change in the coefficients. with the exception of ethnicity, cls_students, and pic_outfit where the change in the coefficient is between 3% and 4% all other variables changed by less than 1%. 
```{r}
# Fit the linear model without 'cls_profs'
m_reduced <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval +
                cls_students + cls_level + cls_credits + bty_avg +
                pic_outfit + pic_color, data = evals)

# summary of the reduced linear model
model_summary_reduced <- summary(m_reduced)
print(model_summary_reduced)

```


15. Using backward-selection and p-value as the selection criterion,
    determine the best model. You do not need to show all steps in your
    answer, just the output for the final model. Also, write out the linear
    model for predicting score based on the final model you settle on.

**Insert your answer here**
Steps to fit the final model
***Starting with the Full Model:*** Fit the model with all predictors.
***Iteratively Remove Variables:*** Based on the p-values, iteratively remove p-value > 0.05
***Final Model:*** Continue until all variables in the model are significant (p-values below 0.05).

```{r}
m_full <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg 
             + pic_outfit + pic_color, data = evals)
summary(m_full)
```

**Best Model**
```{r}
m_final <- lm(score ~ gender + ethnicity + language + age + cls_perc_eval 
             + cls_credits + bty_avg 
             + pic_color, data = evals)
summary(m_final)
```
**equation for best model**
\[
  \widehat{score} = 3.771922 + 0.207112 - 0.167872 - 0.206178 - 0.006046 \times age
  + 0.004656 \times cls_perc_eval + 0.505306 + 0.051069 \times bty_avg - 0.190579
\]

\[
  \widehat{score} = 3.919711 - 0.006046 \times age
  + 0.004656 \times cls_perc_eval + 0.051069 \times bty_avg
\]


16. Verify that the conditions for this model are reasonable using diagnostic 
    plots.

**Insert your answer here**
Below are the diagnostic plots and analsis.

**Residuals vs Fitted Plot:** In this plot, there seems to be no clear pattern, which is a good sign. However, there is a slight funnel shape, suggesting potential heteroscedasticity.

**Normal Q-Q Plot:** The plot shows that most points lie on the line, but there are deviations at the ends. This indicates that the residuals are nearly, but not perfectly, normally distributed.

**Scale-Location (Spread-Location) Plot:** There seems to be a consistent spread, but with slight variations, hinting at possible, but not severe, heteroscedasticity.

**Residuals vs Leverage Plot:** There are a few points with high leverage, but they don't seem to have large residuals. Thus, while there are influential points, they may not be adversely affecting the model too much.

Overall, the model appears to meet the assumptions reasonably well, though there are indications of minor deviations from ideal conditions.

```{r}
library(ggplot2)
library(dplyr)
library(gridExtra)

# Add residuals and fitted values to the data frame
evals <- evals %>%
  mutate(fitted_values = fitted(best_model),
         residuals = resid(best_model),
         sqrt_abs_resid = sqrt(abs(residuals)),
         leverage = hatvalues(best_model))

# Create the plots
plot1 <- ggplot(evals, aes(x = fitted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept=0, color="red", linetype="dashed") +
  labs(title = "Residuals vs Fitted", x = "Fitted values", y = "Residuals")

plot2 <- ggplot(evals, aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line(slope=1, intercept=0, color="red", linetype="dashed") +
  labs(title = "Normal Q-Q", x = "Theoretical Quantiles", y = "Sample Quantiles")

plot3 <- ggplot(evals, aes(x = fitted_values, y = sqrt_abs_resid)) +
  geom_point() +
  labs(title = "Scale-Location Plot", x = "Fitted values", y = "Sqrt(|Residuals|)")

plot4 <- ggplot(evals, aes(x = leverage, y = residuals)) +
  geom_point() +
  geom_hline(yintercept=0, color="red", linetype="dashed") +
  labs(title = "Residuals vs Leverage", x = "Leverage", y = "Residuals")

# Combining the plots into a single grid layout
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2, nrow = 2)

```

17. The original paper describes how these data were gathered by taking a
    sample of professors from the University of Texas at Austin and including 
    all courses that they have taught. Considering that each row represents a 
    course, could this new information have an impact on any of the conditions 
    of linear regression?

**Insert your answer here**
Yes, the new information about how the data were gathered can have significant implications for the conditions and assumptions underlying linear regression analysis. Here are a few key points to consider:

The fact that each row in the dataset represents a course taught by professors at the University of Texas at Austin impacts the assumptions of linear regression. Specifically, courses taught by the same professor may not be independent, violating a key assumption of linear regression. Additionally, the variability in scores could differ across different types of courses (advanced vs. basic), affecting the assumption of constant variance (homoscedasticity). Therefore, the data might require analysis using methods that account for these potential dependencies and clustering, like hierarchical linear modeling.

18. Based on your final model, describe the characteristics of a professor and 
    course at University of Texas at Austin that would be associated with a high
    evaluation score.

**Insert your answer here**
Based on the final linear regression model for professors' evaluations at the University of Texas at Austin, certain characteristics are associated with higher evaluation scores. These include specific aspects of the professor's demographic profile, such as gender, ethnicity, and age, indicating potential influences of identity and experience on evaluations. Language proficiency is also a key factor, suggesting the importance of effective communication in the classroom. Additionally, the beauty average (bty_avg) hints at a potential bias in student evaluations based on physical appearance. Course-related factors like the percentage of class evaluations completed and the number of course credits play a role as well, reflecting aspects of course engagement and intensity. Finally, the influence of the professor's picture color might indicate the impact of perceived professionalism on student evaluations.

19. Would you be comfortable generalizing your conclusions to apply to professors
    generally (at any university)? Why or why not?

**Insert your answer here**
Generalizing the conclusions from this model to professors at all universities should be done cautiously. The data is specific to the University of Texas at Austin, which may have unique characteristics not representative of other institutions. Differences in student populations, teaching styles, and institutional cultures can significantly influence evaluation scores. Furthermore, the model may not account for all relevant variables affecting teaching evaluations, and factors like societal biases could vary across different universities. Therefore, while the findings are valuable for the specific context, applying them universally requires further research in diverse educational settings.

* * *
